{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장 순환 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 14.1 순환 뉴런\n",
    "    - 14.1.1 메모리 셀\n",
    "    - 14.1.2 입력과 출력 시퀀스\n",
    "- 14.2 텐서플로로 기본 RNN 구성하기\n",
    "    - 14.2.1 정적으로 타임 스텝 펼치기\n",
    "    - 14.2.2 동적으로 타임 스텝 펼치기\n",
    "    - 14.2.3 가변 길이 입력 시퀀스 다루기\n",
    "    - 14.2.4 가변 길이 출력 시퀀스 다루기\n",
    "- 14.3 RNN 훈련하기\n",
    "    - 14.3.1 시퀀스 분류기 훈련하기\n",
    "    - 14.3.2 시계열 예측을 위해 훈련하기\n",
    "    - 14.3.3 RNN의 창조성\n",
    "- 14.4 심층 RNN\n",
    "    - 14.4.1 여러 GPU에 심층 RNN 분산하기\n",
    "    - 14.4.2 드롭아웃 적용하기\n",
    "    - 14.4.3 많은 타임 스텝에서 훈련의 어려움\n",
    "- 14.5 LSTM 셀\n",
    "    - 14.5.1 핍홀 연결\n",
    "- 14.6 GRU 셀\n",
    "- 14.7 자연어 처리\n",
    "    - 14.7.1 워드 임베딩\n",
    "    - 14.7.2 기계 번역을 위한 인코더-디코더 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 텐서보드 쥬피터 안에 그리기\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import numpy as np    \n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 순환 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.1 메모리 셀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.2 입력과 출력 시퀀스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 텐서플로로 기본 RNN 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#미니배치:                  샘플0,    샘플1,   샘플2,   샘플3\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t =0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1:X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0664006   0.9625767   0.68105793  0.7091854  -0.898216  ]\n",
      " [ 0.9977755  -0.719789   -0.9965761   0.9673924  -0.9998972 ]\n",
      " [ 0.99999774 -0.99898803 -0.9999989   0.9967762  -0.9999999 ]\n",
      " [ 1.         -1.         -1.         -0.99818915  0.9995087 ]]\n",
      "[[ 1.         -1.         -1.          0.4020025  -0.9999998 ]\n",
      " [-0.12210419  0.62805265  0.9671843  -0.9937122  -0.2583937 ]\n",
      " [ 0.9999983  -0.9999994  -0.9999975  -0.85943305 -0.9999881 ]\n",
      " [ 0.99928284 -0.99999815 -0.9999058   0.9857963  -0.92205757]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1 정적으로 타임 스텝 펼치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-1d3811a73315>:1: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                   dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t =0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t =1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val, S = sess.run([Y0, Y1, states], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30741334 -0.32884315 -0.6542847  -0.9385059   0.52089024]\n",
      " [ 0.99122757 -0.9542541  -0.7518079  -0.9995208   0.9820235 ]\n",
      " [ 0.9999268  -0.99783254 -0.8247353  -0.9999963   0.99947774]\n",
      " [ 0.996771   -0.68750614  0.8419969   0.9303911   0.8120684 ]]\n",
      "[[ 0.99998885 -0.99976057 -0.0667929  -0.9999803   0.99982214]\n",
      " [-0.6524943  -0.51520866 -0.37968948 -0.5922594  -0.08968379]\n",
      " [ 0.99862397 -0.99715203 -0.03308626 -0.9991566   0.9932902 ]\n",
      " [ 0.99681675 -0.9598194   0.39660627 -0.8307606   0.79671973]]\n",
      "[[ 0.99998885 -0.99976057 -0.0667929  -0.9999803   0.99982214]\n",
      " [-0.6524943  -0.51520866 -0.37968948 -0.5922594  -0.08968379]\n",
      " [ 0.99862397 -0.99715203 -0.03308626 -0.9991566   0.9932902 ]\n",
      " [ 0.99681675 -0.9598194   0.39660627 -0.8307606   0.79671973]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)\n",
    "print(Y1_val)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀스 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs,\n",
    "                                                   dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # t= 0, t =1\n",
    "        [[0, 1, 2],[9, 8 ,7]],\n",
    "        [[3, 4, 5],[0, 0, 0]],\n",
    "        [[6, 7, 8],[6, 5, 4]],\n",
    "        [[9, 0, 1],[3, 2, 1]],\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]\n",
      "  [-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999997 ]]\n",
      "\n",
      " [[-0.8001535  -0.9921827   0.7817797   0.9971032  -0.9964609 ]\n",
      "  [-0.637116    0.11300927  0.5798437   0.4310559  -0.6371699 ]]\n",
      "\n",
      " [[-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]\n",
      "  [-0.9165386  -0.9945604   0.896054    0.99987197 -0.9999751 ]]\n",
      "\n",
      " [[ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]\n",
      "  [-0.02746338 -0.73191994  0.7827872   0.9525682  -0.9781773 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999997 ]\n",
      " [-0.637116    0.11300927  0.5798437   0.4310559  -0.6371699 ]\n",
      " [-0.9165386  -0.9945604   0.896054    0.99987197 -0.9999751 ]\n",
      " [-0.02746338 -0.73191994  0.7827872   0.9525682  -0.9781773 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.transpose(outputs_val, axes=[1, 0, 2])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(outputs_val, axes=[1, 0, 2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2 동적으로 타임 스텝 펼치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        [[0, 1, 2], [9, 8, 7]],\n",
    "        [[3, 4, 5], [0, 0, 0]],\n",
    "        [[6, 7, 8], [6, 5, 4]],\n",
    "        [[9, 0, 1], [3, 2, 1]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.85115266  0.87358344  0.5802911   0.8954789  -0.0557505 ]\n",
      "  [-0.999996    0.99999577  0.9981815   1.          0.37679607]]\n",
      "\n",
      " [[-0.9983293   0.9992038   0.98071456  0.999985    0.25192663]\n",
      "  [-0.7081804  -0.0772338  -0.85227895  0.5845349  -0.78780943]]\n",
      "\n",
      " [[-0.9999827   0.99999535  0.9992863   1.          0.5159072 ]\n",
      "  [-0.9993956   0.9984095   0.83422637  0.99999976 -0.47325212]]\n",
      "\n",
      " [[ 0.87888587  0.07356028  0.97216916  0.9998546  -0.7351168 ]\n",
      "  [-0.9134514   0.3600957   0.7624866   0.99817705  0.80142   ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3 가변 길이 입력 시퀀스 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                       sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        [[0, 1, 2],[9, 8, 7]], # 샘플 0\n",
    "        [[3, 4, 5],[0, 0, 0]], # 샘플 1 (0 벡터로 패딩됨)\n",
    "        [[6, 7, 8],[6, 5, 4]], # 샘플 2\n",
    "        [[9, 0, 1],[3, 2, 1]], # 샘플 3\n",
    "])\n",
    "\n",
    "seq_length_batch = np.array([2, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "            [outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.9123188   0.16516446  0.5548655  -0.39159346  0.20846416]\n",
      "  [-1.          0.956726    0.99831694  0.99970174  0.96518576]]\n",
      "\n",
      " [[-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.99999976  0.8967997   0.9986295   0.9647514   0.93662   ]\n",
      "  [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]]\n",
      "\n",
      " [[-0.96435434  0.99501586 -0.36150697  0.9983378   0.999497  ]\n",
      "  [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]]\n",
      "\n",
      "\n",
      "[[-1.          0.956726    0.99831694  0.99970174  0.96518576]\n",
      " [-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586]\n",
      " [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]\n",
      " [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val, end='\\n\\n\\n')\n",
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서  \n",
    "[[-1.          0.956726    0.99831694  0.99970174  0.96518576]  \n",
    " [-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586] # t = 0일때  \n",
    " [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]  \n",
    " [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.4 가변 길이 출력 시퀀스 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 RNN 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.1 시퀀스 분류기 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                                         logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)/255.0\n",
    "X_test = X_test.astype(np.float32)/255.0\n",
    "\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.6333333 검증 세트 정확도: 0.6472\n",
      "1 배치 데이터 정확도: 0.75333333 검증 세트 정확도: 0.766\n",
      "2 배치 데이터 정확도: 0.78 검증 세트 정확도: 0.8292\n",
      "3 배치 데이터 정확도: 0.84 검증 세트 정확도: 0.8584\n",
      "4 배치 데이터 정확도: 0.86 검증 세트 정확도: 0.8408\n",
      "5 배치 데이터 정확도: 0.87333333 검증 세트 정확도: 0.8746\n",
      "6 배치 데이터 정확도: 0.9266667 검증 세트 정확도: 0.9026\n",
      "7 배치 데이터 정확도: 0.8933333 검증 세트 정확도: 0.902\n",
      "8 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9074\n",
      "9 배치 데이터 정확도: 0.8933333 검증 세트 정확도: 0.9166\n",
      "10 배치 데이터 정확도: 0.9266667 검증 세트 정확도: 0.9166\n",
      "11 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.9254\n",
      "12 배치 데이터 정확도: 0.9066667 검증 세트 정확도: 0.9096\n",
      "13 배치 데이터 정확도: 0.94666666 검증 세트 정확도: 0.9208\n",
      "14 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.9326\n",
      "15 배치 데이터 정확도: 0.9266667 검증 세트 정확도: 0.928\n",
      "16 배치 데이터 정확도: 0.94666666 검증 세트 정확도: 0.944\n",
      "17 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.939\n",
      "18 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9456\n",
      "19 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9392\n",
      "20 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9318\n",
      "21 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9424\n",
      "22 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9394\n",
      "23 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.9546\n",
      "24 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9454\n",
      "25 배치 데이터 정확도: 0.9266667 검증 세트 정확도: 0.9368\n",
      "26 배치 데이터 정확도: 0.93333334 검증 세트 정확도: 0.9422\n",
      "27 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9514\n",
      "28 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9476\n",
      "29 배치 데이터 정확도: 0.91333336 검증 세트 정확도: 0.9574\n",
      "30 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9444\n",
      "31 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.9502\n",
      "32 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9566\n",
      "33 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9604\n",
      "34 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9618\n",
      "35 배치 데이터 정확도: 0.94666666 검증 세트 정확도: 0.9622\n",
      "36 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.952\n",
      "37 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9622\n",
      "38 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.967\n",
      "39 배치 데이터 정확도: 0.94666666 검증 세트 정확도: 0.957\n",
      "40 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.957\n",
      "41 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9604\n",
      "42 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9646\n",
      "43 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9592\n",
      "44 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9618\n",
      "45 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9638\n",
      "46 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9574\n",
      "47 배치 데이터 정확도: 0.94666666 검증 세트 정확도: 0.9522\n",
      "48 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9674\n",
      "49 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9684\n",
      "50 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9666\n",
      "51 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9696\n",
      "52 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.9554\n",
      "53 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9658\n",
      "54 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9672\n",
      "55 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9738\n",
      "56 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9718\n",
      "57 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9632\n",
      "58 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9636\n",
      "59 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9694\n",
      "60 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9762\n",
      "61 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9706\n",
      "62 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9746\n",
      "63 배치 데이터 정확도: 0.99333334 검증 세트 정확도: 0.966\n",
      "64 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9702\n",
      "65 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9734\n",
      "66 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9732\n",
      "67 배치 데이터 정확도: 0.99333334 검증 세트 정확도: 0.9736\n",
      "68 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9734\n",
      "69 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.975\n",
      "70 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9698\n",
      "71 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9688\n",
      "72 배치 데이터 정확도: 0.94666666 검증 세트 정확도: 0.9732\n",
      "73 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.972\n",
      "74 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9702\n",
      "75 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9708\n",
      "76 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.971\n",
      "77 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9708\n",
      "78 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9728\n",
      "79 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9728\n",
      "80 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9782\n",
      "81 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9786\n",
      "82 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9704\n",
      "83 배치 데이터 정확도: 0.9533333 검증 세트 정확도: 0.9668\n",
      "84 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9788\n",
      "85 배치 데이터 정확도: 0.96666664 검증 세트 정확도: 0.9754\n",
      "86 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9686\n",
      "87 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9734\n",
      "88 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9774\n",
      "89 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9732\n",
      "90 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9712\n",
      "91 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9728\n",
      "92 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9762\n",
      "93 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9796\n",
      "94 배치 데이터 정확도: 0.97333336 검증 세트 정확도: 0.9748\n",
      "95 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9676\n",
      "96 배치 데이터 정확도: 0.99333334 검증 세트 정확도: 0.9732\n",
      "97 배치 데이터 정확도: 0.99333334 검증 세트 정확도: 0.978\n",
      "98 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.9754\n",
      "99 배치 데이터 정확도: 0.9866667 검증 세트 정확도: 0.979\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y:y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y:y_valid})\n",
    "        \n",
    "        print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.2 시계열 예측을 위해 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t * 5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next_batch(1, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11216173]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_max - t_min - n_steps * resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3 RNN의 창조성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 심층 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.1 여러 GPU에 심층 RNN 분산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2 드롭아웃 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.3 많은 타임 스텝에서 훈련의 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.5 LSTM 셀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5.1 핍홀 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6 GRU 셀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.7 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.1 워드 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.2 기계 번역을 위한 인코더-디코더 네트워크"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
